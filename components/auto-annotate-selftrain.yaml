name: Selftrain
description: |
  Automatically annotate a dataset for selftraining
inputs:
  - {name: image, description: '', default: ''}
  - {name: s3_bucket, description: '', default: ''}
  - {name: owner, description: '', default: ''}
  - {name: project, description: '', default: ''}
  - {name: experiment, description: '', default: ''}
  - {name: dataset, description: '', default: ''}
  - {name: user_model, description: '', default: ''}
  - {name: agent_model, description: '', default: ''}
  - {name: additional_args, description: '', default: ''}
outputs:
  - {name: s3_datadir}
implementation:
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -ex
    - -c
    - |
      . /opt/genie-toolkit/lib.sh
      parse_args "$0" "image s3_bucket owner project experiment dataset user_model agent_model s3_datadir" "$@"
      shift $n
      cd $HOME

      /opt/genie-toolkit/sync-repos.sh
      MAKEDIR=`get_make_dir ${project}`
      GENIE=/opt/genie-toolkit/dist/tool/genie.js

      set +x
      keyctl session ; export AZCOPY_SPA_CLIENT_SECRET=${AZURE_SP_PASSWORD} ; azcopy login --service-principal --application-id ${AZURE_SP_APP_ID} --tenant-id ${AZURE_SP_TENANT_ID}
      set -x

      cat >> workdir/config.mk <<EOF
      developer_key = ${THINGPEDIA_DEVELOPER_KEY}
      EOF
      cd workdir/${MAKEDIR}

      azcopy cp ${s3_bucket%/}/gcampax/dataset/multiwoz/baseline21/train_dials.json train_dials.json
      azcopy sync --recursive "${user_model}" ${experiment}/models/nlu-user --exclude-pattern "iteration_*.pth;*_optim.pth;*/cache/*;*/dataset/*"
      azcopy sync --recursive "${agent_model}" ${experiment}/models/nlu-agent --exclude-pattern "iteration_*.pth;*_optim.pth;*/cache/*;*/dataset/*"

      make \
        geniedir=/opt/genie-toolkit \
        "owner=${owner}" \
        "genie_k8s_owner=${owner}" \
        "genie_k8s_project=${project}" \
        "s3_bucket=geniehai" \
        thingpedia_cli=thingpedia \
        experiment="${experiment}" \
        datadir/selftrain $@

      S3_DATADIR=${s3_bucket%/}/${owner}/dataset/${project}/${experiment}/${dataset}-selftrain/`date +%s`/
      azcopy sync --recursive datadir/selftrain ${S3_DATADIR}user/
      mkdir -p `dirname $s3_datadir`
      echo ${S3_DATADIR}  > $s3_datadir

    args: [
      'cmd',
      --image, {inputValue: image},
      --s3_bucket, {inputValue: s3_bucket},
      --owner, {inputValue: owner},
      --project, {inputValue: project},
      --experiment, {inputValue: experiment},
      --dataset, {inputValue: dataset},
      --user_model, {inputValue: user_model},
      --agent_model, {inputValue: agent_model},
      --s3_datadir, {outputPath: s3_datadir},
      --, {inputValue: additional_args}
    ]
