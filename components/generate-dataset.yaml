name: Generate dataset
description: |
  Generate dataset
inputs:
  - {name: image, description: '', default: ''}
  - {name: s3_bucket, description: '', default: ''}
  - {name: owner, description: '', default: ''}
  - {name: project, description: '', default: ''}
  - {name: experiment, description: '', default: ''}
  - {name: dataset, description: '', default: ''}
  - {name: parallel, description: '', default: ''}
  - {name: valid_set, description: '', default: ''}
  - {name: additional_args, description: '', default: ''}
outputs:
  - {name: s3_datadir}
  - {name: MLPipeline UI metadata, type: UI metadata}
implementation:
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -ex
    - -c
    - |
      . /opt/genie-toolkit/lib.sh
      parse_args "$0" "image s3_bucket owner project experiment dataset parallel valid_set s3_datadir" "$@"
      shift $n
      cd $HOME

      /opt/genie-toolkit/sync-repos.sh
      MAKEDIR=`get_make_dir ${project}`

      set +x
      keyctl session ; export AZCOPY_SPA_CLIENT_SECRET=${AZURE_SP_PASSWORD} ; azcopy login --service-principal --application-id ${AZURE_SP_APP_ID} --tenant-id ${AZURE_SP_TENANT_ID}
      set -x

      cat >> workdir/config.mk <<EOF
      developer_key = ${THINGPEDIA_DEVELOPER_KEY}
      EOF
      cd workdir/${MAKEDIR}

      export TZ=America/Los_Angeles
      make "-j${parallel}" \
          geniedir=/opt/genie-toolkit \
          "owner=${owner}" \
          "genie_k8s_owner=${owner}" \
          "genie_k8s_project=${project}" \
          "s3_bucket=${s3_bucket}" \
          thingpedia_cli=thingpedia \
          "experiment=${experiment}" \
          "valid_set=${valid_set}"\
          $@ \
          datadir
      
      S3_DATADIR=${owner}/dataset/${project}/${experiment}/${dataset}/`date +%s`/
      azcopy sync --recursive datadir/ ${s3_bucket%/}/${S3_DATADIR}
      mkdir -p `dirname $s3_datadir`
      echo ${S3_DATADIR}  > $s3_datadir

      if test -f datadir/stats ; then
        cat > /tmp/mlpipeline-ui-metadata.json <<EOF
      {"outputs" : [
          {
            "storage": "inline",
            "source": "$(cat datadir/stats | tr '\t' ',')",
            "format": "csv",
            "type": "table",
            "header": [ "set", "# dlgs", "# synthetic turns",
              "# training turns", "entropy (ctx)", "entropy (utt)",
              "entropy (tgt)", "turns / dialogues", "# unique ctxs"
            ]
          }
      ]}
      EOF
      else
        echo '{"outputs":[]}' > /tmp/mlpipeline-ui-metadata.json
      fi

    args: [
      'cmd',
      --image, {inputValue: image},
      --s3_bucket, {inputValue: s3_bucket},
      --owner, {inputValue: owner},
      --project, {inputValue: project},
      --experiment, {inputValue: experiment},
      --dataset, {inputValue: dataset},
      --parallel, {inputValue: parallel},
      --valid_set, {inputValue: valid_set},
      --s3_datadir, {outputPath: s3_datadir},
      --, {inputValue: additional_args}
    ]

    fileOutputs:
      MLPipeline UI metadata: /tmp/mlpipeline-ui-metadata.json
