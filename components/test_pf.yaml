name: Test PF
description: |
  Test PF
inputs:
  - {name: image, description: '', default: ''}
  - {name: owner, description: '', default: ''}
  - {name: eval_sets, description: '', default: ''}
  - {name: task_name, description: '', default: ''}
  - {name: model_name_or_path, description: '', default: ''}
  - {name: s3_input_datadir, description: '', default: ''}
  - {name: s3_database_dir, description: '', default: ''}
  - {name: s3_bootleg_prepped_data, description: '', default: ''}
  - {name: model_type, description: '', default: ''}
  - {name: dataset_subfolder, description: '', default: ''}
  - {name: val_batch_size, description: '', default: ''}
  - {name: additional_args, description: '', default: ''}
outputs:
  - {name: metrics_output}
  - {name: s3_metrics_output}
  - {name: MLPipeline UI metadata, type: UI metadata}
  - {name: MLPipeline Metrics, type: Metrics}
implementation:
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -ex
    - -c
    - |
      . /opt/genie-toolkit/lib.sh
      parse_args "$0" "image owner eval_sets task_name model_name_or_path s3_input_datadir s3_database_dir s3_bootleg_prepped_data model_type dataset_subfolder metrics_output s3_metrics_output val_batch_size" "$@"
      shift $n
      cd $HOME

      /opt/genie-toolkit/sync-repos.sh

      git clone https://github.com/tunib-ai/parallelformers.git
      cd parallelformers
      pip3 install -e .

      python3 tests/seq2seq_lm.py "--test-name=FP32 & Non-PF" --name=Helsinki-NLP/opus-mt-en-zh --gpu-from=0 --gpu-to=2 $@


    args: [
      'cmd',
      --image, {inputValue: image},
      --owner, {inputValue: owner},
      --eval_sets, {inputValue: eval_sets},
      --task_name, {inputValue: task_name},
      --model_name_or_path, {inputValue: model_name_or_path},
      --s3_input_datadir, {inputValue: s3_input_datadir},
      --s3_database_dir, {inputValue: s3_database_dir},
      --s3_bootleg_prepped_data, {inputValue: s3_bootleg_prepped_data},
      --model_type, {inputValue: model_type},
      --dataset_subfolder, {inputValue: dataset_subfolder},
      --s3_metrics_output, {outputPath: s3_metrics_output},
      --metrics_output, {outputPath: metrics_output},
      --val_batch_size, {inputValue: val_batch_size},
      --, {inputValue: additional_args}
    ]

    fileOutputs:
      MLPipeline UI metadata: /tmp/mlpipeline-ui-metadata.json
      MLPipeline Metrics: /tmp/mlpipeline-metrics.json
