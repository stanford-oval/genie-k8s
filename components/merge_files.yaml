name: Merge
description: |
  Merge files
inputs:
  - {name: image, description: '', default: ''}
  - {name: s3_bucket, description: ''}
  - {name: s3_datadir, description: '', default: ''}
  - {name: s3_bootleg_prepped_data, description: ''}
  - {name: data_splits, description: '', default: ''}

outputs:
  - {name: s3_output_datadir}

implementation:
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -ex
    - -c
    - |
      . /opt/genie-toolkit/lib.sh
      parse_args "$0" "image s3_datadir s3_bootleg_prepped_data data_splits s3_output_datadir" "$@"
      shift $n
      cd $HOME

      /opt/genie-toolkit/sync-repos.sh

      set +x
      keyctl session ; export AZCOPY_SPA_CLIENT_SECRET=${AZURE_SP_PASSWORD} ; azcopy login --service-principal --application-id ${AZURE_SP_APP_ID} --tenant-id ${AZURE_SP_TENANT_ID}
      set -x

      mkdir -p dataset/merged
      cd dataset/

      echo ${s3_bootleg_prepped_data}

      for s3_folder in ${s3_bootleg_prepped_data}; do
        azcopy sync --recursive=true ${s3_bucket%/}/${s3_folder} .
        for split in ${data_splits} ; do
          cat ${split}_bootleg/bootleg_wiki/bootleg_labels.jsonl >> merged/${split}_bootleg_labels.jsonl
          rm -rf ${split}_bootleg
        done
      done

      # uses timestamp from the last bootleg step
      s3_bootleg_prepped_parsed=`echo ${s3_folder} | sed 's/^.*\/bootleg\//\/bootleg\//'`

      for split in ${data_splits} ; do
        azcopy cp merged/${split}_bootleg_labels.jsonl ${s3_bucket%/}/${s3_datadir%/}/merged${s3_bootleg_prepped_parsed%/}/${split}_bootleg/bootleg_wiki/bootleg_labels.jsonl
      done

      mkdir -p `dirname $s3_output_datadir`
      echo ${s3_datadir%/}/merged${s3_bootleg_prepped_parsed%/}/ > $s3_output_datadir

    args: [
      'cmd',
      --image, {inputValue: image},
      --s3_bucket, {inputValue: s3_bucket},
      --s3_datadir, {inputValue: s3_datadir},
      --s3_bootleg_prepped_data, {inputValue: s3_bootleg_prepped_data},
      --data_splits, {inputValue: data_splits},
      --s3_output_datadir, {outputPath: s3_output_datadir},
    ]
