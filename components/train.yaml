name: Train
description: |
  Training
inputs:
  - {name: image, description: ''}
  - {name: s3_bucket, description: ''}
  - {name: owner, description: ''}
  - {name: task_name, description: ''}
  - {name: project, description: ''}
  - {name: experiment, description: ''}
  - {name: model, description: ''}
  - {name: load_from, description: ''}
  - {name: eval_set, description: ''}
  - {name: s3_datadir, description: ''}
  - {name: s3_database_dir, description: ''}
  - {name: dataset_subfolder, description: ''}
  - {name: train_iterations, description: ''}
  - {name: skip_tensorboard, description: ''}
  - {name: train_languages, description: ''}
  - {name: eval_languages, description: ''}
  - {name: dlg_side, description: ''}
  - {name: do_ner, description: '', default: 'false'}
  - {name: s3_bootleg_prepped_data, description: '', default: ''}
  - {name: bootleg_model, description: '', default: ''}
  - {name: additional_args, description: ''}
outputs:
  - {name: s3_model_dir}
implementation:
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -ex
    - -c
    - |
      . /opt/genie-toolkit/lib.sh

      parse_args "$0" "image s3_bucket owner task_name project experiment model load_from s3_datadir s3_database_dir dataset_subfolder s3_model_dir skip_tensorboard train_languages eval_languages eval_set dlg_side do_ner s3_bootleg_prepped_data bootleg_model" "$@"
      shift $n
      cd $HOME

      /opt/genie-toolkit/sync-repos.sh

      IFS='+' ; read -ra TLS <<<"$train_languages"; IFS=' '
      echo "${TLS[@]}"
      IFS='+'; read -ra ELS <<<"$eval_languages"; IFS=' '
      echo "${ELS[@]}"

      modeldir="$HOME/models/$model"
      mkdir -p "$modeldir"

      if test "${s3_database_dir}" != None ; then
        aws s3 sync --no-progress ${s3_database_dir} ./database/ --exclude '*' --include '*wikidataqid_to_bootlegtypeid.json' --include '*entityQID_to_wikidataTypeQID.json' --include "*${bootleg_model}/*.json"
      fi

      if test "${s3_bootleg_prepped_data}" != None ; then
        aws s3 sync --no-progress ${s3_bootleg_prepped_data} results_temp
      fi

      load_args=
      if test "${load_from}" != None ; then
        aws s3 sync --no-progress "${load_from}" "$modeldir"/ --exclude "iteration_*.pth" --exclude "*eval/*"  --exclude "*.log"
        load_args="--load best.pth"
      fi

      mkdir -p cache

      case $task_name in
        *"multilingual"*)
          for lang in "${TLS[@]}" "${ELS[@]}" ; do
            aws s3 sync --no-progress ${s3_datadir} dataset/almond/multilingual --exclude "*/*" --include "*$lang*"
          done
        ;;

        *)
          aws s3 sync --no-progress --exclude "synthetic*.txt" ${s3_datadir} dataset/almond
        ;;
      esac

      mkdir -p "/shared/tensorboard/${project}/${experiment}/${owner}/${model}"

      tensorboard_args=
      if test "$skip_tensorboard" != "true" ; then
        tensorboard_args="--tensorboard_dir /shared/tensorboard/${project}/${experiment}/${owner}/${model}"
      fi

      bootleg_args=
      if test "$do_ner" == "true" ; then
        bootleg_args="--bootleg_model ${bootleg_model} --bootleg_input_dir ./database/"
      fi

      genienlp train \
          --data "dataset" \
          --save "$modeldir" \
          --cache "cache" \
          --train_tasks ${task_name} \
          --preserve_case \
          --exist_ok \
          --skip_cache \
          --eval_set_name $eval_set \
          --train_languages $train_languages \
          --eval_languages $eval_languages \
          ${tensorboard_args} \
          ${load_args} \
          ${bootleg_args} \
          $@

      rm -fr "$modeldir/cache"
      rm -fr "$modeldir/dataset"

      S3_MODEL_DIR=s3://${s3_bucket}/${owner}/models/${project}/${experiment}/${model}/`date +%s`/
      aws s3 sync --no-progress ${modeldir}/ ${S3_MODEL_DIR}

      mkdir -p `dirname $s3_model_dir`
      echo ${S3_MODEL_DIR} > $s3_model_dir

    args: [
      'cmd',
      --image, {inputValue: image},
      --s3_bucket, {inputValue: s3_bucket},
      --owner, {inputValue: owner},
      --task_name, {inputValue: task_name},
      --project, {inputValue: project},
      --experiment, {inputValue: experiment},
      --model, {inputValue: model},
      --eval_set, {inputValue: eval_set},
      --load_from, {inputValue: load_from},
      --s3_datadir, {inputValue: s3_datadir},
      --s3_database_dir, {inputValue: s3_database_dir},
      --dataset_subfolder, {inputValue: dataset_subfolder},
      --s3_model_dir, {outputPath: s3_model_dir},
      --skip_tensorboard, {inputValue: skip_tensorboard},
      --train_languages, {inputValue: train_languages},
      --eval_languages, {inputValue: eval_languages},
      --dlg_side, {inputValue: dlg_side},
      --do_ner, {inputValue: do_ner},
      --s3_bootleg_prepped_data, {inputValue: s3_bootleg_prepped_data},
      --bootleg_model, {inputValue: bootleg_model},
      --,
      --train_iterations, {inputValue: train_iterations},
      {inputValue: additional_args}, 
    ]
    
