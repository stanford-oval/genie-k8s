name: Eval
description: |
  Evaluate a SimpleTOD model
inputs:
  - {name: owner, description: ''}
  - {name: project, description: ''}
  - {name: experiment, description: ''}
  - {name: s3_datadir, description: ''}
  - {name: s3_model_dir, description: ''}
  - {name: image, description: ''}
  - {name: additional_args, description: ''}
outputs:
  - {name: metrics_output}
  #- {name: MLPipeline UI metadata, type: UI metadata}
  #- {name: MLPipeline Metrics, type: Metrics}
implementation:
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -e
    - -c
    - |
      . k8s/lib.sh
      
      parse_args "$0" "image owner project experiment s3_datadir s3_model_dir metrics_output" "$@"
      shift $n
      set -x
      
      aws s3 sync --no-progress ${s3_datadir} resources/
      aws s3 sync --no-progress ${s3_model_dir} output/
      
      checkpoints=$(ls output/distilgpt2/ | grep -o '[0-9]*')
      
      mkdir -p `dirname $metrics_output`
      touch $metrics_output
      
      for f in output/distilgpt2/checkpoint-* ; do
          echo $f >> $metrics_output
          python3 generate_dialogue.py --checkpoint $f --split_set test
          python3 compute_joint_acc.py --eval_file *.json >> $metrics_output
          cat $metrics_output
      done
      echo 'done'
      cat $metrics_output

    args: [
      'cmd',
      --image, {inputValue: image},
      --owner, {inputValue: owner},
      --project, {inputValue: project},
      --experiment, {inputValue: experiment},
      --s3_datadir, {inputValue: s3_datadir},
      --s3_model_dir, {inputValue: s3_model_dir},
      --metrics_output, {outputPath: metrics_output},
      --, {inputValue: additional_args}
    ]

    #fileOutputs:
    #  MLPipeline UI metadata: /tmp/mlpipeline-ui-metadata.json
    #  MLPipeline Metrics: /tmp/mlpipeline-metrics.json