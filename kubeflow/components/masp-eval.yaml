name: Eval
description: |
  Eval MaSP model
inputs:
  - {name: image, description: '', default: ''}
  - {name: owner, description: '', default: ''}
  - {name: model, description: '', default: ''}
  - {name: model_id, description: '', default: ''}
  - {name: timeout, description: '', default: ''}
  - {name: num_parallels, description: '', default: ''}
  - {name: additional_args, description: '', default: ''}
outputs:
  - {name: s3_model_dir}
implementation: 
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -ex
    - -c
    - |
      . /opt/genie-toolkit/lib.sh
      parse_args "$0" "image owner model model_id timeout num_parallels s3_model_dir" "$@"
      shift $n
      cd $HOME
      ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1
              export LD_LIBRARY_PATH=/sbin/ldconfig.real:/usr/lib/x86_64-linux-gnu:/usr/local/cuda-9.0/targets/x86_64-linux/lib:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs:$LD_LIBRARY_PATH
      
      curl https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip  > bert_base.zip
      unzip -q bert_base.zip -d .
      mv "uncased_L-12_H-768_A-12" bert_base
      
      cd /opt/MaSP
      git log --pretty=format:'%H' -n 1
      git pull origin master
      git log --pretty=format:'%H' -n 1
      
      #aws s3 sync --no-progress s3://geniehai/${owner}/dataset/csqa/BFS/test data/BFS/test
      aws s3 sync --no-progress s3://geniehai/${owner}/dataset/csqa/BFS/test_proc_direct_1000_wo_con data/BFS/test
      aws s3 sync --no-progress s3://geniehai/${owner}/dataset/csqa/kb data/kb
      aws s3 sync --no-progress s3://geniehai/${owner}/dataset/csqa/EDL data/EDL
      aws s3 cp --no-progress s3://geniehai/${owner}/dataset/csqa/BFS/wikidata.pkl data/BFS/wikidata.pkl
      aws s3 cp --no-progress s3://geniehai/${owner}/dataset/csqa/BFS/type_kb.pkl data/BFS/type_kb.pkl
      aws s3 cp --no-progress s3://geniehai/${owner}/dataset/csqa/BFS/pre_type.pkl data/BFS/pre_type.pkl
      
      S3_MODEL_DIR=s3://geniehai/${owner}/models/csqa/${model}/${model_id}
      
      aws s3 sync --no-progress ${S3_MODEL_DIR}/ckpt runtime/run_model/${model}/ckpt/
      aws s3 sync --no-progress ${S3_MODEL_DIR}/preproc runtime/preproc
      
      python3 /opt/MaSP/main_e2e.py --mode parallel_test --network_class bert --network_type bert_template \
      --dataset e2e_wo_con \
      --preprocessing_hparams bert_pretrained_dir=bert_base,timeout=${timeout},num_parallels=${num_parallels},dump_dir=multi_sp,kb_mode=offline,verbose_test=True,use_filtered_ent=True \
      --training_hparams load_model=True,load_path=runtime/run_model/${model}/ckpt \
      --model_dir_prefix parallel_decoding \
      --gpu 0
      
      aws s3 sync --no-progress runtime/run_model/parallel_decoding/log_files ${S3_MODEL_DIR}/eval
      
      mkdir -p `dirname $s3_model_dir`
      echo ${S3_MODEL_DIR} > $s3_model_dir

    args: [
      'cmd',
      --image, {inputValue: image},
      --owner, {inputValue: owner},
      --model, {inputValue: model},
      --model_id, {inputValue: model_id},
      --timeout, {inputValue: timeout},
      --num_parallels, {inputValue: num_parallels},
      --s3_model_dir, {outputPath: s3_model_dir},
      --,
      {inputValue: additional_args}, 
    ]