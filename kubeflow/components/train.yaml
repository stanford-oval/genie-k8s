name: Train
description: |
  Training
inputs:
  - {name: image, description: '', default: ''}
  - {name: s3_bucket, description: '', default: ''}
  - {name: owner, description: '', default: ''}
  - {name: dataset_owner, description: '', default: ''}
  - {name: task_name, description: '', default: '' }
  - {name: project, description: '', default: ''}
  - {name: experiment, description: '', default: ''}
  - {name: dataset, description: '', default: ''}
  - {name: model, description: '', default: ''}
  - {name: load_from, description: '', default: ''}
  - {name: additional_args, description: '', default: ''}
outputs:
  - {name: model_path}
implementation:
  container:
    image: '{{inputs.parameters.image}}'
    command:
    - /bin/bash
    - -ex
    - -c
    - |
      . /opt/genie-toolkit/lib.sh

      parse_args "$0" "image s3_bucket owner dataset_owner task_name project experiment dataset model load_from model_path" "$@"
      shift $n 
      pwd
      cd $HOME

      modeldir="$HOME/models/$model"
      mkdir -p "$modeldir"

      if ! test  ${load_from} = 'None' ; then
          aws s3 sync ${load_from}/ "$modeldir"/ --exclude "iteration_*.pth" --exclude "*eval/*"  --exclude "*.log"
      fi

      aws s3 sync --exclude "synthetic*.txt" s3://${s3_bucket}/${dataset_owner}/dataset/${project}/${experiment}/${dataset} dataset/

      rm -fr "$modeldir/dataset"
      mkdir "$modeldir/dataset"
      rm -fr "$modeldir/cache"
      mkdir -p "$modeldir/cache"
      ln -s "$HOME/dataset" "$modeldir/dataset/almond"
      ln -s $modeldir /home/genie-toolkit/current
      mkdir -p "/shared/tensorboard/${project}/${experiment}/${owner}/${model}"
     
      genienlp train \
          --data "$modeldir/dataset" \
          --embeddings ${GENIENLP_EMBEDDINGS} \
          --save "$modeldir" \
          --tensorboard_dir "/shared/tensorboard/${project}/${experiment}/${owner}/${model}" \
          --cache "$modeldir/cache" \
          --train_tasks ${task_name} \
          --preserve_case \
          --save_every 1000 \
          --log_every 100 \
          --val_every 1000 \
          --exist_ok \
          --skip_cache \
          $@ 

      rm -fr "$modeldir/cache"
      rm -fr "$modeldir/dataset"
      aws s3 sync ${modeldir}/ s3://${s3_bucket}/${owner}/models/${project}/${experiment}/${model}
            
      mkdir -p `dirname $model_path`
      echo "s3://${s3_bucket}/${owner}/models/${project}/${experiment}/${model}" > $model_path
    
    args: [
      'cmd',
      --image, {inputValue: image},
      --s3_bucket, {inputValue: s3_bucket},
      --owner, {inputValue: owner},
      --dataset_owner, {inputValue: dataset_owner},
      --task_name, {inputValue: task_name},
      --project, {inputValue: project},
      --experiment, {inputValue: experiment},
      --dataset, {inputValue: dataset},
      --model, {inputValue: model},
      --load_from, {inputValue: load_from},
      --model_path, {outputPath: model_path},
      --, {inputValue: additional_args}, 
    ]
    
